# Lightweight-tuning-to-Foundational-model--GEN-AI

# PEFT with LoRA for Sequence Classification

This project demonstrates parameter-efficient fine-tuning (PEFT) using the LoRA technique on a GPT-2 model for binary sentiment classification on the IMDb dataset.

## ğŸ§  Key Concepts
- LoRA (Low-Rank Adaptation)
- Sequence classification
- GPT-2 adaptation with Hugging Face
- PEFT using `peft` library

## ğŸš€ How to Run
1. Clone the repo
2. Install dependencies: `pip install -r requirements.txt`
3. Run the notebook: `LightweightFineTuning.py`

## ğŸ“ Output
- Trained PEFT model saved in `saved_model`
- Baseline vs. fine-tuned accuracy comparison
